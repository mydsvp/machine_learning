{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3a50dc",
   "metadata": {},
   "source": [
    " ## Generative AI Architecture model for Agriculture Smart City\n",
    " #### Developer: Matthew Yeseta, Gen AI Architect\n",
    "### Gen AI Python Model. \n",
    "This model is a comprehensive implementation of a Generative AI model designed for Agriculture Smart City application with custom data set uploaded to HuggingFaces for the embedded data model.\n",
    "This Gen AI model integrates prompt engineering, image analysis, and model fine-tuning for optimizing agricultural processes using advanced AI techniques.\n",
    "\n",
    "\n",
    "##### Generative AI Architecture model for Agriculture Smart City\n",
    "The implementation of a Generative AI model designed for Agriculture Smart City application with custom data set uploaded to HuggingFaces for the embedded data model. My Gen AI model integrates prompt engineering, image analysis, and model fine-tuning for optimizing agricultural processes using advanced AI techniques.\n",
    "\n",
    "##### Generative AI Architecture Prompt Engineering\n",
    "Prompt Engineering patterns were appropriately evaluated and this Agriculture Smart City HuggingFaces\n",
    "base prompt for China client business person role, zero shot classification prompts, chain of thought prompts, chaining prompts, and memory agent action prompts for complete coverage of all patterns for prompt engineering. \n",
    "\n",
    "##### Generative AI Architecture Fine Tuning\n",
    "Fine tuning models were explored for prompt engineering for performance, the models test and implemented for this LLM Gen AI were evaluated and tested: PEFT, LoRA, RLHF\n",
    " \n",
    "Parameter-Efficient Fine-Tuning (PEFT) method for LLM LangChain LoRA (Low-Rank Adaptation) fine tuning for LLM and scalable LLM solutions on generative models Generative Agent Retrieval-Augmented Learning Human Feedback (RLHF) \n",
    " \n",
    "Fine tuning models were explored for prompt engineering performance, the models test and implemented for this LLM Gen AI were evaluated and tested: PEFT, LoRA, RLHF \n",
    " \n",
    "This model utilized Parameter-Efficient Fine-Tuning (PEFT) method for LLM LangChain, also fine tune LLM for scalable LLM solutions using LoRA (Low-Rank Adaptation), and evaluated the Generative Agent Retrieval-Augmented Learning Human Feedback (RLHF) to ensure prompt engineering for performance was sufficient to move forward with the delivery     \n",
    "\n",
    "#### Below has more detailed summary of each part of the code for the Gen AI Hubbing faces Fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05c3718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matth\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, pipeline\n",
    "from langchain.chains import LLMChain, SequentialChain  \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor \n",
    "import openai\n",
    "import rank_bm25\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303064b",
   "metadata": {},
   "source": [
    "### Generative AI Architecture model for Agricuture Smart City\n",
    "### Imports and Setup:\n",
    "#### Transformers and LangChain:\n",
    "Imports modules from transformers for tokenization and model handling (TFAutoModelForSeq2SeqLM for TensorFlow-based models).\n",
    "LangChain components are imported for building chains, managing prompts, and handling memory.\n",
    "Additional Libraries: numpy for numerical operations, matplotlib for plotting, and cv2 (OpenCV) for image processing.\n",
    " \n",
    "FAISS and Embeddings: Used for vector-based retrieval and handling embeddings with HuggingFaceEmbeddings and\n",
    "OpenAIEmbeddings. Pretrained Model Initialization:\n",
    "#### Model and Tokenizer:\n",
    " Loads the T5 model (t5-large) and tokenizer using TensorFlow, configured for sequence-to-sequence language modeling tasks.\n",
    " Embedding Models:\n",
    " Initializes embeddings using a custom model (Ag_smart_city/land_water_nutrients_data) and OpenAI embeddings for document\n",
    " vectorization.\n",
    "#### FAISS Vector Store:\n",
    " Creates a FAISS-based vector store from text embeddings for efficient similarity search and retrieval.\n",
    "#### Ensemble Retriever:\n",
    " Combines multiple retrievers (FAISS and potentially BM25) into an EnsembleRetriever with specified weights to enhance retrieval\n",
    " accuracy for downstream tasks.\n",
    "#### Function to Instantiate LLM:\n",
    " instantiate_LLM: This function initializes a language model interface (ChatOpenAI) using OpenAI's GPT models. It configures the model\n",
    " with specific parameters like temperature and top-p for controlling response variability\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_smartcity_land = \"t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(ag_smartcity_land)\n",
    "ag_smartcity_land = TFAutoModelForSeq2SeqLM.from_pretrained(ag_smartcity_land)\n",
    "embedding_data = \"Ag_smart_city/land_water_nutrients_data\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_smart_city_model)\n",
    "embedding = OpenAIEmbeddings()\n",
    "faiss_vectorstore = FAISS.from_texts(\n",
    "    embedding_data, embedding_model, metadatas=[{\"source\": 2}] * len(embedding_data)\n",
    ")\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retrievers = [faiss_retriever]  \n",
    "weights = [1.0]  \n",
    "if bm25_retriever:\n",
    "    retrievers.append(bm25_retriever)\n",
    "    weights.append(0.5)\n",
    "retriever = EnsembleRetriever(retrievers=retrievers, weights=weights) if len(retrievers) > 1 else faiss_retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d09be",
   "metadata": {},
   "source": [
    "#### Generative AI Architecture model for Agricuture Smart City\n",
    "#### Function for LLM Large Langage Model\n",
    " Instantiate_LLM: This function initializes a language model interface (ChatOpenAI) using OpenAI's GPT models. It configures the model\n",
    " with specific parameters like temperature and top-p for controlling response variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56e37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_LLM(LLM_provider,\n",
    "    api_key, \n",
    "    temperature=0.5, top_p=0.95, \n",
    "    model_name=None):\n",
    "    \n",
    "    if LLM_provider == \"OpenAI\":\n",
    "        llm = ChatOpenAI(\n",
    "            api_key=api_key,\n",
    "            model=model_name if model_name else \"gpt-3.5-turbo\",\n",
    "            temperature=temperature,\n",
    "            model_kwargs={\"top_p\": top_p}\n",
    "        )\n",
    "        return llm\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported LLM provider: {LLM_provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1813d",
   "metadata": {},
   "source": [
    " #### Generative AI Architecture model for Agricuture Smart City\n",
    " ### Function for LLM Image Analysis\n",
    " #### Function Analyze_vehicle_routes:\n",
    " Detects and counts vehicle routes in an image using edge detection and contour finding techniques.\n",
    "#### Function detect_water_levels\n",
    " \n",
    " Identifies water regions in an image by color segmentation in the HSV color space, and calculates the percentage of the image covered by water.\n",
    "#### Function annotate_image_with_lat_long:\n",
    " Adds markers and annotations to an image at specified latitude and longitude points.\n",
    "#### Function analyze_land_growth:\n",
    " Computes the Normalized Difference Vegetation Index (NDVI) for an image to assess plant health and growth.\n",
    "#### Function analyze_nutrient_levels:\n",
    " Detects regions with specific nutrient levels by analyzing green areas in the image through color segmentation.\n",
    "#### Latitude and Longitude Points for Agriculture:\n",
    " lat_long_points_agriculture_coordinates: Provides a list of predefined geographic coordinates used for analysis and annotation in the image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0202fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_vehicle_routes(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found. Unable to read image.\")\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    min_contour_area = 100  # Minimum contour area to be considered a vehicle route\n",
    "    route_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, route_contours, -1, (0, 255, 0), 2)\n",
    "    route_count = len(route_contours)\n",
    "        \n",
    "    return route_contours, route_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a701ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_water_levels(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        raise FileNotFoundError(\"Image not found. Unable to read image.\")\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([90, 50, 50])\n",
    "    upper_blue = np.array([140, 255, 255])\n",
    "    mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "    water_regions = cv2.bitwise_and(image, image, mask=mask)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 3)  \n",
    "    water_area = cv2.countNonZero(mask)\n",
    "    total_area = image.shape[0] * image.shape[1]\n",
    "    water_level_percentage = (water_area / total_area) * 100\n",
    "    \n",
    "    return water_level_percentage, water_level_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719261fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image_with_lat_long(image, lat_long_points):\n",
    "    for point in lat_long_points:\n",
    "        lat, lon, x, y = point\n",
    "        cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.putText(image, f\"({lat}, {lon})\", (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    return image\n",
    "def analyze_land_growth(image_path, lat_long_points):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found. Or incorrect path.\")\n",
    "    float_image = image.astype(float)\n",
    "    Blue, Green, Red = cv2.split(image)\n",
    "    NIR = Red.astype(float)\n",
    "    Red_channel = Green.astype(float)\n",
    "    NDVI = (NIR - Red_channel) / (NIR + Red_channel + 1e-10)  \n",
    "    NDVI_normalized = ((NDVI + 1) / 2 * 255).astype(np.uint8)\n",
    "    ndvi_colormap = cv2.applyColorMap(NDVI_normalized, cv2.COLORMAP_JET)\n",
    "    annotated_image = annotate_image_with_lat_long(ndvi_colormap, lat_long_points)\n",
    "    return annotated_image, NDVI\n",
    "\n",
    "def analyze_water_levels(image_path, lat_long_points):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found. Or incorrect path.\")\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, water_mask = cv2.threshold(gray_image, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "    annotated_image = annotate_image_with_lat_long(water_mask, lat_long_points)\n",
    "    \n",
    "    return annotated_image, water_mask\n",
    "def analyze_nutrient_levels(image_path, lat_long_points):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found. Or incorrect path.\")\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([35, 100, 100])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "    green_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    nutrient_analysis_image = cv2.bitwise_and(image, image, mask=green_mask)\n",
    "    annotated_image = annotate_image_with_lat_long(nutrient_analysis_image, lat_long_points)\n",
    "    \n",
    "    return annotated_image, green_mask\n",
    "def lat_long_points_agriculture_coordinates():\n",
    "    lat_long_points = [\n",
    "        (38.4632, -121.3705), (38.5265, -121.4117), (38.5238, -121.5184), (38.6111, -121.4968),\n",
    "        (38.4517, -121.4849), (38.6052, -121.3891), (38.5479, -121.5412), (38.4600, -121.4083),\n",
    "        (38.5154, -121.4708), (38.5125, -121.3972), (38.4748, -121.5479), (38.4801, -121.4149),\n",
    "        (38.5643, -121.5032), (38.5966, -121.4727), (38.4825, -121.4336), (38.5542, -121.3853),\n",
    "        (38.5890, -121.4291), (38.4698, -121.5258), (38.6037, -121.5176), (38.5137, -121.5264),\n",
    "        (38.4933, -121.4480), (38.5726, -121.4042), (38.4660, -121.4595), (38.5517, -121.4352),\n",
    "        (38.4762, -121.4951), (38.5137, -121.5264)\n",
    "    ]    \n",
    "    return lat_long_points_agriculture_coordinates        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e53d5",
   "metadata": {},
   "source": [
    "#### Generative AI Architecture model for Agricuture Smart City\n",
    "####  Class for Handling OpenAI Prompts:\n",
    "###### AgWaterNutrientsOpenAIPrompts:\n",
    " This class manages the creation and fine-tuning of prompts for analyzing the impact of water and nutrient levels on agriculture.\n",
    "#### Prompt engineering techniques for GPT OpenAI chat for business users\n",
    "Zero-shot, few-shot, and chain-of-thought prompts for generating strategies and analyses.\n",
    "#### Gen AI Fine Tuning: PEFT, LORA, RLHF models for optimization:\n",
    " Three methods for fine tuning optimization were developed and each provided fine tuning implemenation for the models for each custom prompt tuning based on user feedback and specific instructions.\n",
    "###### 1. Parameter-Efficient Fine-Tuning (PEFT)\n",
    "###### 2. Low-Rank Adaptation (LoRA)\n",
    "###### 3. Reinforcement Learning with Human Feedback (RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c9f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgWaterNutrientsOpenAIPrompts:\n",
    "    def __init__(self, api_key, model=\"gpt-3.5-turbo\", temperature=0.5, model_kwargs=None):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.model_kwargs = model_kwargs or {}\n",
    "        self.base_model = TFAutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        \n",
    "    @staticmethod\n",
    "    def ag_tomato_zero_shot_prompt():\n",
    "        ag_tomato_zero_shot_prompt = \"Analyze agricultural potential impact of water/nutrients levels on land managed locations by Lat/Long points and city resources for water.\"\n",
    "        return ag_tomato_zero_shot_prompt\n",
    "    \n",
    "    @staticmethod\n",
    "    def ag_tomato_few_shot_prompt():\n",
    "        ag_tomato_few_shot_prompt = \"\"\"\n",
    "        Determine the best agricultural strategy for water/nutrients land management.\n",
    "        agricultural_strategy1: High water/nutrients levels in Lat/Long points led to increased tomato production.\n",
    "        agricultural_strategy2: Low water/nutrients levels in Lat/Long points necessitated the use of drought-resistant crops.\n",
    "        agricultural_strategy3: Lat/Long points experiencing moderate water/nutrients levels for tomato crops. What has the remote team experienced, positive or negative?\n",
    "        \"\"\"\n",
    "        return ag_tomato_few_shot_prompt\n",
    "    \n",
    "    @staticmethod\n",
    "    def ag_tomato_chain_of_thought_prompt():\n",
    "        ag_tomato_chain_of_thought_prompt = \"\"\"\n",
    "        agricultural_chain1: Analyze the current water/nutrients levels applied in Lat/Long points.\n",
    "        agricultural_chain2: Predict the impact on the crop yield in Lat/Long points.\n",
    "        agricultural_chain3: Suggest the optimal crops for planting given the water/nutrients availability.\n",
    "        \"\"\"\n",
    "        return ag_tomato_chain_of_thought_prompt\n",
    "    \n",
    "    @staticmethod\n",
    "    def ag_tomato_prompt_chaining_prompts():\n",
    "        ag_tomato_prompt_chaining_prompts = [\n",
    "            \"Evaluate current water levels for one or many Lat/Long points.\",\n",
    "            \"Analyze impact for one or many Lat/Long points on production on water levels on crop yields for tomato.\",\n",
    "            \"Provide recommendations for optimal crop selection for one or many Lat/Long points.\"\n",
    "        ]\n",
    "        return ag_tomato_prompt_chaining_prompts\n",
    "    \n",
    "    @staticmethod\n",
    "    def ag_tomato_memory_agent_action_prompt():\n",
    "        ag_tomato_memory_agent_action_prompt = \"\"\"\n",
    "        Based on suppliers' data collected in the valley from contacts showing historical water level data and nutrients levels, which have been sufficient to support new smart city resources.\n",
    "        \"\"\"\n",
    "        return ag_tomato_memory_agent_action_prompt\n",
    "\n",
    "    def PEFT_fine_tuning(self, dataset):\n",
    "        print(\"Parameter-Efficient Fine-Tuning (PEFT)\")\n",
    "        for data in dataset:\n",
    "            input_ids = self.tokenizer(data['prompt'], return_tensors='tf').input_ids\n",
    "            labels = self.tokenizer(data['response'], return_tensors='tf').input_ids\n",
    "            outputs = self.base_model(input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            print(f\"Fine-tuning step - Loss: {loss.numpy()}\")\n",
    "        print(\"PEFT completed.\")\n",
    "    \n",
    "    def LoRA_fine_tuning(self, dataset):\n",
    "        print(\"Low-Rank Adaptation (LoRA)...\")\n",
    "        for data in dataset:\n",
    "            input_ids = self.tokenizer(data['prompt'], return_tensors='tf').input_ids\n",
    "            labels = self.tokenizer(data['response'], return_tensors='tf').input_ids\n",
    "            outputs = self.base_model(input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            print(f\"Fine-tuning step - Loss: {loss.numpy()}\")\n",
    "        print(\"LoRA fine-tuning completed.\")\n",
    "    \n",
    "    def RLHF_fine_tuning(self, dataset, reward_model):\n",
    "        print(\"Reinforcement Learning with Human Feedback (RLHF)\")\n",
    "        for data in dataset:\n",
    "            input_ids = self.tokenizer(data['prompt'], return_tensors='tf').input_ids\n",
    "            labels = self.tokenizer(data['response'], return_tensors='tf').input_ids\n",
    "            outputs = self.base_model(input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            reward = reward_model.evaluate(outputs)\n",
    "            print(f\"Fine-tuning step - Loss: {loss.numpy()}, Reward: {reward}\")\n",
    "        print(\"RLHF fine-tuning completed.\")\n",
    "    \n",
    "    def prompt_fine_tuning(self, prompt, context_window=128, feedback=None):\n",
    "        print(\"Prompt Tuning with context window...\")\n",
    "        tokenized_prompt = self.tokenizer(prompt, return_tensors='tf').input_ids\n",
    "        print(f\"Original prompt tokenized: {tokenized_prompt}\")\n",
    "        if tokenized_prompt.shape[1] > context_window:\n",
    "            adjusted_prompt = tokenized_prompt[:, :context_window]\n",
    "            print(f\"Truncated prompt to fit within context window of size {context_window}.\")\n",
    "        else:\n",
    "            adjusted_prompt = tokenized_prompt\n",
    "            print(f\"Prompt fits within the context window. No truncation needed.\")\n",
    "        adjusted_prompt_text = self.tokenizer.decode(adjusted_prompt[0], skip_special_tokens=True)\n",
    "        print(f\"Adjusted prompt text: {adjusted_prompt_text}\")\n",
    "        response = self.base_model.generate(adjusted_prompt)\n",
    "        response_text = self.tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "        print(f\"Generated response: {response_text}\")\n",
    "        if feedback:\n",
    "            print(f\"Applying feedback: {feedback}\")\n",
    "            if feedback.lower() == \"too formal\":\n",
    "                print(\"Adjusting for a more casual response...\")\n",
    "                response = self.base_model.generate(adjusted_prompt, temperature=0.7)  # Increase temperature for more casual tone\n",
    "                response_text = self.tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "            elif feedback.lower() == \"too long\":\n",
    "                print(\"Shortening the response...\")\n",
    "                response = self.base_model.generate(adjusted_prompt, max_length=context_window // 2)  # Reduce response length\n",
    "                response_text = self.tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "            print(f\"Adjusted response based on feedback: {response_text}\")\n",
    "        return response_text\n",
    "    \n",
    "    def fine_tune_with_instructions(self, dataset, context_window=128):\n",
    "        print(\"LLM instructions with context window\")\n",
    "        for data in dataset:\n",
    "            input_ids = self.tokenizer(data['prompt'], return_tensors='tf').input_ids\n",
    "            labels = self.tokenizer(data['response'], return_tensors='tf').input_ids\n",
    "            print(f\"Fine-tuning on context window of size {context_window} for prompt: {data['prompt']}\")\n",
    "            outputs = self.base_model(input_ids[:, :context_window], labels=labels[:, :context_window])\n",
    "            loss = outputs.loss\n",
    "            print(f\"Fine-tuning step - Loss: {loss.numpy()}\")\n",
    "        print(\"Fine-tuning with instructions completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c6ddd",
   "metadata": {},
   "source": [
    "#### Generative AI Architecture model for Agricuture Smart City\n",
    "####  Class for AI Model Interactions:\n",
    "#### AgricultureAI:\n",
    " Facilitates various AI-based analyses including zero-shot and few-shot classifications, prompt chaining, and memory-based actions using the language model. It integrates with image analysis functions to process agricultural data and provide insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d166c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgricultureAI:\n",
    "    def __init__(self, model, tokenizer, rag):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.rag = rag\n",
    "        \n",
    "    def zero_shot_classification(self, prompt):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(**inputs)\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    \n",
    "    def few_shot_classification(self, prompt):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(**inputs)\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    \n",
    "    def chain_of_thought(self, prompt):\n",
    "        steps = prompt.split(\"\\n\")\n",
    "        responses = []\n",
    "        for step in steps:\n",
    "            inputs = self.tokenizer(step, return_tensors=\"pt\")\n",
    "            outputs = self.model.generate(**inputs)\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            responses.append(response)\n",
    "        return responses\n",
    "    \n",
    "    def prompt_chaining(self, prompts):\n",
    "        responses = []\n",
    "        for prompt in prompts:\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "            outputs = self.model.generate(**inputs)\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            responses.append(response)\n",
    "        return responses\n",
    "    \n",
    "    def memory_agent_action(self, prompt, memory_buffer):\n",
    "        memory = ConversationBufferMemory()\n",
    "        agent = MemoryAgent(memory=memory)\n",
    "        memory.add(prompt)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(**inputs)\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        action = f\"Based on the memory: {memory_buffer}, the action taken is: {response}\"\n",
    "        memory.add(action)\n",
    "        return response, action\n",
    "    \n",
    "    def detect_water_levels(self, image_path):\n",
    "        water_level_percentage, water_level_image = detect_water_levels(image_path)\n",
    "        return water_level_percentage, water_level_image\n",
    "    \n",
    "    def vehicle_route_analysis(self, image_path):\n",
    "        vehicle_routes, routes_detected = analyze_vehicle_routes(image_path)\n",
    "        return vehicle_routes, routes_detected\n",
    "    \n",
    "    def analyze_land_growth(self, image_path):\n",
    "        lat_long_points = lat_long_points_agriculture_coordinates\n",
    "        image = annotate_image_with_lat_long(image, lat_long_points)        \n",
    "        land_growth_image, NDVI = analyze_land_growth(image_path, lat_long_points)\n",
    "        water_levels_image, water_mask = analyze_water_levels(image_path, lat_long_points)\n",
    "        nutrient_levels_image, nutrient_mask = analyze_nutrient_levels(image_path, lat_long_points)\n",
    "        return growth_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb15a59",
   "metadata": {},
   "source": [
    "#### Generative AI Architecture model for Agricuture Smart City\n",
    "#### Prompt Generation Based on User Roles:\n",
    "###### get_prompts:\n",
    " Provides role-specific prompts for different user roles (agriculture manager, architect, planner) to guide AI in generating appropriate responses and actions for each role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8fad72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(user_role):\n",
    "    if user_role == \"agriculture_manager\":\n",
    "        return {\n",
    "            \"zero_shot\": \"Analyze the impact of current water and nutrient levels on agricultural land productivity for given Lat/Long points.\",\n",
    "            \"few_shot\": \"\"\"\n",
    "            Examples:\n",
    "            - High water and nutrient levels in certain regions led to increased tomato production.\n",
    "            - Low water and nutrient levels required the use of drought-resistant crops.\n",
    "            Region X is experiencing moderate water and nutrient levels. What strategy would you suggest?\n",
    "            \"\"\",\n",
    "            \"chain_of_thought\": \"\"\"\n",
    "            Step 1: Evaluate the current water and nutrient levels for the specified lat/long points.\n",
    "            Step 2: Predict the impact on tomato crop yield.\n",
    "            Step 3: Recommend the optimal crops for planting given the current conditions.\n",
    "            \"\"\",\n",
    "            \"prompt_chaining\": [\n",
    "                \"Evaluate current water levels for the specified lat/long points.\",\n",
    "                \"Analyze the impact of these water levels on tomato crop yield.\",\n",
    "                \"Provide recommendations for optimal crop selection given the current conditions.\"\n",
    "            ],\n",
    "            \"memory_agent_action\": \"\"\"\n",
    "            Given historical water and nutrient data, predict the tomato crop yield for specific lat/long regions.\"\n",
    "            \"\"\"\n",
    "        }\n",
    "    elif user_role == \"architect\":\n",
    "        return {\n",
    "            \"zero_shot\": \"Design a sustainable water and nutrient management plan for agricultural regions with specific Lat/Long points.\",\n",
    "            \"few_shot\": \"\"\"\n",
    "            Examples:\n",
    "            - Implementing efficient irrigation systems in water-scarce areas led to significant improvements in the crop yield in Lat/Long points\n",
    "            - Introducing advanced nutrient management techniques reduced wastage and increased soil fertility.\n",
    "            For region Y, design a plan to optimize water and nutrient usage.\n",
    "            \"\"\",\n",
    "            \n",
    "            \"chain_of_thought\": \"\"\"\n",
    "            Step 1: Assess the current water and nutrient infrastructure in the specified region.\n",
    "            Step 2: Identify potential improvements in irrigation and nutrient distribution systems.\n",
    "            Step 3: Propose a sustainable plan for long-term water and nutrient management.\n",
    "            \"\"\",\n",
    "            \"prompt_chaining\": [\n",
    "                \"Assess the current state of water and nutrient infrastructure for the specified lat/long points.\",\n",
    "                \"Identify areas for improvement in irrigation and nutrient distribution.\",\n",
    "                \"Design a comprehensive plan to optimize water and nutrient usage sustainably.\"\n",
    "            ],\n",
    "            \"memory_agent_action\": \"\"\"\n",
    "            Based on historical infrastructure data and current conditions, design a sustainable water and nutrient management plan for smart city\"\n",
    "            \"\"\"\n",
    "        }\n",
    "    elif user_role == \"planner\":\n",
    "        return {\n",
    "            \"zero_shot\": \"Plan the allocation of water and nutrients to maximize agricultural productivity in various in Lat/Long points.\",\n",
    "            \"few_shot\": \"\"\"\n",
    "            Examples:\n",
    "            - Allocating more water to regions with high crop demands resulted in better yields.\n",
    "            - Adjusting nutrient distribution based on soil quality led to more efficient use of resources.\n",
    "            For region Z, how would you allocate water and nutrients to maximize productivity?\n",
    "            \"\"\",\n",
    "            \"chain_of_thought\": \"\"\"\n",
    "            Step 1: Review the current allocation of water and nutrients in the specified regions.\n",
    "            Step 2: Analyze the productivity impact of the current allocation.\n",
    "            Step 3: Recommend adjustments to optimize the distribution of resources.\n",
    "            \"\"\",\n",
    "            \"prompt_chaining\": [\n",
    "                \"Review the current allocation of water and nutrients for the specified lat/long points.\",\n",
    "                \"Analyze the impact of the current resource allocation on productivity.\",\n",
    "                \"Suggest optimal adjustments to improve resource distribution and maximize productivity.\"\n",
    "            ],\n",
    "            \"memory_agent_action\": \"\"\"\n",
    "            Using historical data on water and nutrient allocation, plan the distribution of resources for specific in Lat/Long points.\"\n",
    "            \"\"\"\n",
    "        }\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124b581",
   "metadata": {},
   "source": [
    "#### Generative AI Architecture model for Agricuture Smart City\n",
    "#### Class for Managing Prompts by Role\n",
    "#### Class AgricultureAIRolesPrompts:\n",
    " Manages and displays prompts for different roles which represents clients in China for the Gen AI prompt engineering session. This class integrates functionality of the AgricultureAI class to execute and print results for prompt engineering AI tasks. There were also fine tune testing. See code on fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40baf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgricultureAIRolesPrompts:\n",
    "  \n",
    "    def base_prompt(self, role):\n",
    "        prompts = get_prompts(role)\n",
    "        print(f\"\\n{role.capitalize()} Prompts:\")\n",
    "        \n",
    "    def zero_shot_classification_prompt(self, role):\n",
    "        zero_shot_result = agriculture_ai.zero_shot_classification(prompts[\"zero_shot\"])\n",
    "        print(f\"Zero-shot classification result for {role}:\\n{zero_shot_result}\\n\")\n",
    "              \n",
    "    def chain_of_thought_prompt(role):\n",
    "        chain_of_thought_result = agriculture_ai.chain_of_thought(prompts[\"chain_of_thought\"])\n",
    "        print(f\"Chain of thought result for {role}:\\n{' '.join(chain_of_thought_result)}\\n\")\n",
    "             \n",
    "    def chaining_prompt(role):\n",
    "        prompt_chaining_result = agriculture_ai.prompt_chaining(prompts[\"prompt_chaining\"])\n",
    "        print(f\"Prompt chaining result for {role}:\\n{' '.join(prompt_chaining_result)}\\n\")               \n",
    "        \n",
    "    def memory_agent_action_prompt(role):\n",
    "        prompts = get_prompts(role)  # Ensure you have the prompts for the given role\n",
    "        memory_buffer = \"Historical data shows varying water and nutrient levels across different lat/long regions.\"\n",
    "        memory_agent_action_result, action = agriculture_ai.memory_agent_action(prompts[\"few_shot\"], memory_buffer)\n",
    "        print(f\"Memory agent action result for {role}:\\n{memory_agent_action_result}\\nAction taken:\\n{action}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4e4b1",
   "metadata": {},
   "source": [
    "#### Main Functionality for Running Prompts and Analysis:\n",
    "#### main_prompts:\n",
    " Initializes the language model and runs various prompt-based analyses for different user roles. It also performs image analysis for smart city to be sustanable in land growth, water levels, and nutrient levels, and displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95563df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_prompts():\n",
    "    api_key = \"your_openai_api_key_here\"\n",
    "    llm = instantiate_LLM(\"OpenAI\", api_key, temperature=0.7, top_p=0.9, model_name=\"gpt-4\")\n",
    "    customer_roles = [\"agriculture_manager\", \"architect\", \"planner\"]\n",
    "    for business_person_role in customer_roles:\n",
    "        \n",
    "        base_prompt(business_person_role)\n",
    "        zero_shot_classification_prompt(business_person_role)\n",
    "        chain_of_thought_prompt(business_person_role)\n",
    "        chaining_prompt(business_person_role)\n",
    "        memory_agent_action_prompt(business_person_role)\n",
    "        \n",
    "    example_image_path = \"path_to_your_image.jpg\"\n",
    "    lat_long_points = lat_long_points_agriculture_coordinates()\n",
    "    land_growth_image, NDVI = agriculture_ai.analyze_land_growth(example_image_path)\n",
    "    cv2.imwrite(\"land_growth_analysis.jpg\", land_growth_image)\n",
    "    \n",
    "    water_level_percentage, water_regions = agriculture_ai.detect_water_levels(example_image_path)\n",
    "    print(f\"Detected Water Level Percentage: {water_level_percentage}%\")\n",
    "    \n",
    "    route_contours, route_count = agriculture_ai.vehicle_route_analysis(example_image_path)\n",
    "    print(f\"Number of detected vehicle routes: {route_count}\")\n",
    "    \n",
    "    nutrient_levels_image, nutrient_mask = agriculture_ai.analyze_nutrient_levels(example_image_path)\n",
    "    cv2.imwrite(\"nutrient_levels_analysis.jpg\", nutrient_levels_image)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Land Growth (NDVI)\")\n",
    "    plt.imshow(cv2.cvtColor(land_growth_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Water Levels\")\n",
    "    plt.imshow(cv2.cvtColor(water_regions, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Nutrient Levels\")\n",
    "    plt.imshow(cv2.cvtColor(nutrient_levels_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1bad2",
   "metadata": {},
   "source": [
    "#### Fine-Tuning Processes:\n",
    "### function fine_tuning\n",
    "  Outlines steps for fine-tuning the language model using different techniques (PEFT, LoRA, RLHF) and adjusting model responses based on feedback and specific instructional contexts\n",
    "  \n",
    "Fine tuning models were explored for prompt enginering performanc, the models test and implemented for this LLM Gen AI were evauated and tested: PEFT, LoRA, RLHF\n",
    "\n",
    "This model utilized Parameter-Efficient Fine-Tuning (PEFT) method for LLM LangChain, also fine tune LLM for scalable LLM solutions using LoRA (Low-Rank Adaptation), and evaluated the Generative Agent Retrieval-Augmented Learning Human Feedback (RLHF) to ensure prompt engineering for performance was sufficient to move forward with the delivery.\n",
    "\n",
    "Let me outline key recommendations in fine-tuning. The Parameter-Efficient Fine-Tuning (PEFT) method. This approach optimizes prompt engineering by efficiently adjusting prompt parameters to enhance model performance. By incorporating a small adapter into the pre-trained model, PEFT reduces the number of parameters required for fine-tuning, resulting in a more effective and computationally efficient model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc862218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuning():\n",
    "    llm.fine_tune_peft(dataset)\n",
    "    llm.fine_tune_lora(dataset)\n",
    "    reward_model = llm.load_reward_model()\n",
    "    llm.rl_fine_tuning(dataset, reward_model)\n",
    "    prompt = \"Explain the effects of climate change on agriculture.\"\n",
    "    llm.prompt_tuning(prompt, context_window=128)\n",
    "    llm.fine_tune_with_instructions(dataset, context_window=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a12e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
