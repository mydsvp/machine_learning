{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc27cec",
   "metadata": {},
   "source": [
    "## Computer Vision using Resnet CNN architecture model\n",
    "\n",
    "#### Matthew Yeseta, Master Data Science, Indiana (3.8/4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0080c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matth\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc830a9d",
   "metadata": {},
   "source": [
    "The DataLoader class is designed to handle the loading and organization of image file paths from a specified directory for use in a machine learning model. This class is initialized with a base directory (base_dir), which it then uses to gather and shuffle the paths to all image files that are located within directories containing the word 'images'. This shuffling is intended to randomize the order of the files, which is a common practice in machine learning to prevent the model from learning any potential order in the data presentation.\n",
    "\n",
    "The method _load_paths is a private method, indicated by the underscore prefix, and it is responsible for walking through the directory structure starting from base_dir. As it explores each directory and its files, it collects paths to the files that are inside directories named with 'images'. After gathering all such paths, it shuffles this list to ensure randomness.\n",
    "\n",
    "Lastly, the split_data method divides the shuffled list of image paths into three subsets: training, validation, and test sets. The sizes of these sets are determined by percentage thresholds, splitting approximately 75% of the data for training and then taking the next 7% for validation, leaving the remainder for testing. This method returns a tuple containing these three lists, which can then be used to train and evaluate a machine learning model. This separation of data is crucial for training robust models that generalize well on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4a6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, base_dir):\n",
    "        self.base_dir = base_dir\n",
    "        self.path_df = self._load_paths()\n",
    "\n",
    "    def _load_paths(self):\n",
    "        path_df = []\n",
    "        for dirname, _, filenames in os.walk(self.base_dir):\n",
    "            for filename in filenames:\n",
    "                if 'images' in dirname:\n",
    "                    path_df.append(os.path.join(dirname, filename))\n",
    "        random.shuffle(path_df)\n",
    "        return path_df\n",
    "\n",
    "    def split_data(self):\n",
    "        train_idx = int(len(self.path_df) * 0.75)\n",
    "        val_idx = int(len(self.path_df) * 0.82)\n",
    "        return (self.path_df[:train_idx], self.path_df[train_idx:val_idx], self.path_df[val_idx:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67b04e",
   "metadata": {},
   "source": [
    "The ImagePreprocessor class contains methods dedicated to processing images, specifically designed for use in a computer vision pipeline. This class operates as a static utility class, meaning it doesn't need to maintain any state and can be called directly on the class itself without needing an instance.\n",
    "\n",
    "The first method, crop_image, takes a single image as input and performs cropping to remove any zero-padding. It identifies the non-zero regions of the image (those areas that actually contain image data as opposed to the padded zeros) and calculates the minimum and maximum boundaries of these regions along both axes. The image is then cropped to this identified bounding box, effectively removing any parts of the image that contain no information.\n",
    "\n",
    "The second method, process_image_paths, is designed to process a list of image file paths. For each path provided, it loads the image in grayscale, converts it into an array, and then calls the crop_image method to remove padding. After cropping, the image is resized to a standard dimension (175x175 pixels in this case). This resized image is then normalized by dividing by 255 to scale pixel values to the range [0, 1], making it suitable for neural network input. This method also extracts the class label from the path name (assumed to be three directories up from the file name) and stores it. Finally, process_image_paths returns two arrays: one containing the processed image data (X) and the other containing the corresponding labels (y). This setup is particularly useful for preparing datasets for training and evaluating machine learning models, where inputs (X) and targets (y) are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aee6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    @staticmethod\n",
    "    def crop_image(image):\n",
    "        nonzero_indices = np.argwhere(image != 0)\n",
    "        y_min, y_max = nonzero_indices[:, 0].min(), nonzero_indices[:, 0].max()\n",
    "        x_min, x_max = nonzero_indices[:, 1].min(), nonzero_indices[:, 1].max()\n",
    "        return image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    @staticmethod\n",
    "    def process_image_paths(image_paths):\n",
    "        X, y = [], []\n",
    "        for path in image_paths:\n",
    "            img = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(path, color_mode='grayscale'))\n",
    "            cropped_img = ImagePreprocessor.crop_image(img)\n",
    "            resized_img = tf.image.resize(cropped_img, (175, 175))\n",
    "            X.append(np.array(resized_img / 255.0, dtype=np.float16))\n",
    "            y.append(path.split('/')[-3])\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96a62d",
   "metadata": {},
   "source": [
    "The ResNetModel class encapsulates the construction and setup of a convolutional neural network model specifically designed in the style of ResNet, which is particularly suited for image classification tasks.\n",
    "\n",
    "Upon instantiation of an object of this class, the __init__ method initializes the neural network model by calling the build_model method. The build_model method defines a sequential model using Keras - a high-level neural networks API. This model starts with a 2D convolutional layer that has 512 filters and a kernel size of 7, and uses 'selu' (Scaled Exponential Linear Unit) as the activation function. The input shape specified corresponds to grayscale images of size 175x175. Following this, a dropout layer is introduced to prevent overfitting by randomly setting a fraction of input units to 0 during training, which in this case is 20% of the units.\n",
    "\n",
    "Subsequently, another 2D convolutional layer with 128 filters and a smaller kernel size of 3 is added, followed by a max pooling layer which helps reduce the spatial dimensions of the output from the previous convolutional layers. The max pooling layer uses a pool size of 3 and a stride of 1, keeping the padding same to maintain the spatial dimensions.\n",
    "\n",
    "The add_residual_units method is then called to insert additional layers into the model. This method iteratively adds groups of residual units to the model, which are essential components in ResNet architectures. These units help the network learn identity functions, which is beneficial for training deeper networks by allowing gradients to flow through the network without vanishing. Each residual unit is configured with a predefined number of filters (128 and 64) and a stride of 2, designed to increase the depth of the model while controlling its complexity and computational demand.\n",
    "\n",
    "After constructing the residual units, the modelâ€™s architecture is finalized by flattening the multi-dimensional inputs into a one-dimensional array, followed by dense (fully connected) layers with 'selu' activation functions and dropout layers. These layers serve to interpret the features extracted by the convolutions and pooling, transforming them into final outputs of the model. The final dense layer uses a 'softmax' activation function, suitable for multi-class classification, outputting the probabilities of the input being in each of four classes.\n",
    "\n",
    "Finally, the model is compiled with a configuration that specifies the 'sparse_categorical_crossentropy' loss function and the 'adam' optimizer, a popular choice for training deep learning models due to its efficient handling of sparse gradients on noisy problems. The accuracy metric is also tracked, which is essential for evaluating the performance of the model during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307e25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(512, 7, strides=2, padding=\"same\", activation=\"selu\", input_shape=(175, 175, 1)),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Conv2D(128, 3, strides=1, padding=\"same\", activation=\"selu\"),\n",
    "            keras.layers.MaxPool2D(pool_size=3, strides=1, padding=\"same\")\n",
    "        ])\n",
    "        \n",
    "        self.add_residual_units(model)\n",
    "        \n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(128, activation='selu'))\n",
    "        model.add(keras.layers.Dropout(0.4))\n",
    "        model.add(keras.layers.Dense(64, activation='selu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "        model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "        \n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def add_residual_units(self, model):\n",
    "        filters = [128] * 2 + [64] * 2\n",
    "        for f in filters:\n",
    "            model.add(ResidualUnit(f, strides=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3250eb",
   "metadata": {},
   "source": [
    "The ResidualUnit class is designed as a custom layer in TensorFlow, extending the capabilities of Keras's Layer class. It represents a building block of a residual neural network, often used in deeper neural networks to help mitigate the vanishing gradient problem. The constructor of this class (__init__) initializes the layer with a specific number of filters, stride, and activation function. The activation function used here is selu by default, which is a type of scaled exponential linear unit that aims to improve learning in deep neural networks by self-normalizing the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19dcaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"selu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(filters, 3, strides=strides, padding=\"same\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters, 3, strides=1, padding=\"same\"),\n",
    "            keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv2D(filters, 1, strides=strides, padding=\"same\"),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60322a2a",
   "metadata": {},
   "source": [
    "The MainWorkflow class is designed to encapsulate the entire process of data loading, model training, and evaluation within a computer vision context using a ResNet model. Upon initialization, the class sets up three main components: a DataLoader to manage data retrieval, a LabelEncoder to encode class labels for use in the model, and a ResNetModel which represents the neural network architecture.\n",
    "\n",
    "The run method of MainWorkflow orchestrates the preprocessing and partitioning of image data into training, validation, and test sets using predefined slices of data paths. This method uses the ImagePreprocessor to handle the loading and preprocessing of image data into a suitable format for the model. Once the data is prepared, the class labels are transformed into a numerical format using the LabelEncoder.\n",
    "\n",
    "The display_results method is responsible for visualizing the outcomes of the model training and evaluation. It predicts class labels for the test data using the trained ResNet model and computes the accuracy against the true labels. A classification report is then generated to provide detailed performance metrics for each class. Additionally, this method plots the training history, showing both accuracy and loss metrics over the course of training, providing a visual representation of the model's training process. These plots help in understanding how well the model learned from the training data and how it performed on the validation data across training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92cc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWorkflow:\n",
    "    def __init__(self, base_dir):\n",
    "        self.loader = DataLoader(base_dir)\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.model = ResNetModel()\n",
    "\n",
    "    def run(self):\n",
    "        X_train, y_train = ImagePreprocessor.process_image_paths(self.loader.path_df[:70])\n",
    "        X_val, y_val = ImagePreprocessor.process_image_paths(self.loader.path_df[70:80])\n",
    "        X_test, y_test = ImagePreprocessor.process_image_paths(self.loader.path_df[80:])\n",
    "\n",
    "        y_train = self.encoder.fit_transform(y_train)\n",
    "        y_val = self.encoder.transform(y_val)\n",
    "        y_test = self.encoder.transform(y_test)\n",
    "\n",
    "\n",
    "    def display_results(self, history, X_test, y_test):\n",
    "        prob_pred_ResNet = self.model.model.predict(X_test)\n",
    "        y_pred_ResNet = np.argmax(prob_pred_ResNet, axis=1)\n",
    "\n",
    "        print('Accuracy on Test Set:', accuracy_score(y_test, y_pred_ResNet))\n",
    "        print('Classification Report:')\n",
    "        print(classification_report(self.encoder.inverse_transform(y_test), self.encoder.inverse_transform(y_pred_ResNet)))\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 7))\n",
    "        plt.title(\"ResNet Model\")\n",
    "        axs[0].plot(history['accuracy'], label='Accuracy')\n",
    "        axs[0].plot(history['val_accuracy'], label='Val Accuracy')\n",
    "        axs[0].legend()\n",
    "        axs[0].grid()\n",
    "\n",
    "        axs[1].plot(history['loss'], label='Loss')\n",
    "        axs[1].plot(history['val_loss'], label='Val Loss')\n",
    "        axs[1].legend()\n",
    "        axs[1].grid()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f760892",
   "metadata": {},
   "source": [
    "Python \"__name__\" main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    workflow = MainWorkflow('/kaggle/input')\n",
    "    workflow.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
